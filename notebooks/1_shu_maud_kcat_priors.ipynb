{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eb8904-ec39-4533-937e-67fa19a382f5",
   "metadata": {},
   "source": [
    "# Maud to shu\n",
    "\n",
    "Example to generate [`shu`](https://github.com/biosustain/shu) inputs from [`Maud`](https://github.com/biosustain/Maud) output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8406b8-7d6f-47fb-be75-87b66729822e",
   "metadata": {},
   "source": [
    "It requires [Maud](https://github.com/biosustain/Maud) and [maudtools](https://github.com/biosustain/maudtools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b028e83-2758-403f-b4c9-9d43e600e960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:03.511069Z",
     "iopub.status.busy": "2023-09-27T15:16:03.508869Z",
     "iopub.status.idle": "2023-09-27T15:16:09.350626Z",
     "shell.execute_reply": "2023-09-27T15:16:09.348524Z",
     "shell.execute_reply.started": "2023-09-27T15:16:03.510982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from math import isnan\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from maud.getting_idatas import get_idata\n",
    "from maud.loading_maud_inputs import MaudInput, load_maud_input\n",
    "from maud.utils import get_lognormal_parameters_from_quantiles\n",
    "from maudtools.plotting import concat_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fd1aa-e42b-4d3f-bd90-3d08d9930804",
   "metadata": {},
   "source": [
    "Load the input that was used to run `maud sample` and the output generated by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98372904-7d47-4843-90a9-f938e48a2849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:09.361608Z",
     "iopub.status.busy": "2023-09-27T15:16:09.359939Z",
     "iopub.status.idle": "2023-09-27T15:16:09.371186Z",
     "shell.execute_reply": "2023-09-27T15:16:09.368590Z",
     "shell.execute_reply.started": "2023-09-27T15:16:09.361518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_RESULTS = \"maud_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aa88f9-25a0-4667-b3b3-fcd2fd4d2979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:09.378021Z",
     "iopub.status.busy": "2023-09-27T15:16:09.376684Z",
     "iopub.status.idle": "2023-09-27T15:16:10.606853Z",
     "shell.execute_reply": "2023-09-27T15:16:10.605001Z",
     "shell.execute_reply.started": "2023-09-27T15:16:09.377939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi = load_maud_input(f\"../data/{OUTPUT_RESULTS}/user_input\")\n",
    "idata = get_idata(glob(f\"../data/{OUTPUT_RESULTS}/samples/*csv\"), mi, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43da32d9-bc64-451f-90a9-2a2c8e7ee192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:10.609882Z",
     "iopub.status.busy": "2023-09-27T15:16:10.609025Z",
     "iopub.status.idle": "2023-09-27T15:16:10.628762Z",
     "shell.execute_reply": "2023-09-27T15:16:10.625766Z",
     "shell.execute_reply.started": "2023-09-27T15:16:10.609806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_experiments(infd, x_var: str = \"reactions\", experiments: list[str] = None):\n",
    "    if experiments is None:\n",
    "        experiments = infd.experiments\n",
    "    with_exp = {\n",
    "        exp.item(): pd.DataFrame(np.concatenate(infd[:, :, i, :]), columns=infd[x_var])\n",
    "        for i, exp in enumerate(experiments)\n",
    "    }\n",
    "    list(map(lambda x: x[1].insert(0, \"experiment\", x[0]), with_exp.items()))\n",
    "    return pd.concat(with_exp.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f367624-b220-46b2-868c-7f97bcca6c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:10.631909Z",
     "iopub.status.busy": "2023-09-27T15:16:10.630721Z",
     "iopub.status.idle": "2023-09-27T15:16:10.644042Z",
     "shell.execute_reply": "2023-09-27T15:16:10.641653Z",
     "shell.execute_reply.started": "2023-09-27T15:16:10.631825Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q_exploc(kcat) -> tuple[float, float, str]:\n",
    "    \"\"\"Calculate mu and sigma of the underlying normal distribution from a Maud prior kcat.\"\"\"\n",
    "    mu, sigma = (\n",
    "        (np.log(kcat.exploc), kcat.scale)\n",
    "        if kcat.exploc is not None\n",
    "        else get_lognormal_parameters_from_quantiles(kcat.pct1, 0.01, kcat.pct99, 0.99)\n",
    "    )   \n",
    "    return mu, sigma, kcat.enzyme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b10a7-9f28-4935-b188-1f36c8e6a7ed",
   "metadata": {},
   "source": [
    "Functions to transform the data from the maud output into shu input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae2735e-6cdb-48fb-b58a-bf79d2d24f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:10.648005Z",
     "iopub.status.busy": "2023-09-27T15:16:10.646528Z",
     "iopub.status.idle": "2023-09-27T15:16:10.693204Z",
     "shell.execute_reply": "2023-09-27T15:16:10.691685Z",
     "shell.execute_reply.started": "2023-09-27T15:16:10.647920Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_to_shu(idata: az.InferenceData, mi: MaudInput) -> Dict[str, List[float]]:\n",
    "    \"\"\"Plot kcats on box-points, enzyme concentrations as hist (prior/posterior), flux as hover and flux mean as color and size of arrows.\"\"\"\n",
    "    # enzyme concentrations and kcats are assigned to enzymes, so we must \n",
    "    # build a map from enzymes to reactions\n",
    "    edge_list = [e.split(\"_\") for e in idata.posterior.edges.to_numpy() if \"_\" in e]\n",
    "    edges = {ed[1]: ed[0] for ed in edge_list}\n",
    "    edges_to_val = {ed[0]: ed[1] for ed in edge_list}\n",
    "\n",
    "    fluxes = concat_experiments(idata.posterior.flux_train, \"reactions\").melt(\n",
    "        id_vars=\"experiment\", var_name=\"reaction\", value_name=\"flux\"\n",
    "    )\n",
    "    # gather enz conc posteriors and priors and translate them to reactions\n",
    "    conc_enzymes = concat_experiments(\n",
    "        idata.posterior.conc_enzyme_train,\n",
    "        \"enzymes\",\n",
    "        idata.posterior.conc_enzyme_train.experiments,\n",
    "    )\n",
    "    conc_enzymes.columns = [\n",
    "        edges_to_val[col] if col != \"experiment\" else \"experiment\"\n",
    "        for col in conc_enzymes.columns\n",
    "    ]\n",
    "    conc_enzymes = conc_enzymes.melt(\n",
    "        id_vars=\"experiment\", var_name=\"reaction\", value_name=\"enzyme\"\n",
    "    )\n",
    "    conc_enzymes[\"experiment\"] = \"Posterior\"\n",
    "    conc_enzymes_priors = pd.DataFrame(\n",
    "        [\n",
    "            (conc_enzyme[2], point, \"Prior\")\n",
    "            for conc_enzyme in [q_exploc(conc_enzyme) for conc_enzyme in mi.prior_input.conc_enzyme]\n",
    "            for point in np.random.lognormal(conc_enzyme[0], conc_enzyme[1], size=300)\n",
    "        ],\n",
    "        columns=[\"reaction\", \"enzyme\", \"experiment\"]\n",
    "    )\n",
    "    conc_enzymes_priors[\"reaction\"] = conc_enzymes_priors.reaction.apply(lambda x: edges_to_val[x])\n",
    "    conc_enzymes = pd.concat([conc_enzymes, conc_enzymes_priors])\n",
    "    # gather kcat posteriors and translate them to reactions\n",
    "    kcats = pd.DataFrame(\n",
    "        np.concatenate(idata.posterior.kcat), columns=idata.posterior[\"enzymes\"]\n",
    "    )\n",
    "    kcats.columns = [edges_to_val[col] for col in kcats.columns]\n",
    "    kcats = kcats.melt(var_name=\"reaction\", value_name=\"kcat\")\n",
    "    kcats[\"experiment\"] = \"Posterior\"\n",
    "\n",
    "    for df in [fluxes, conc_enzymes, kcats]:\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"DRAIN\")]\n",
    "    merged = pd.concat(\n",
    "        [\n",
    "            df.sort_values([\"experiment\", \"reaction\"])\n",
    "            if i == 0\n",
    "            else df.sort_values([\"experiment\", \"reaction\"]).loc[\n",
    "                :, ~df.columns.isin([\"experiment\", \"reaction\"])\n",
    "            ]\n",
    "            for i, df in enumerate([fluxes, kcats])\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    merged.experiment = \"Posterior\"\n",
    "    \n",
    "    merged = pd.merge(merged, conc_enzymes, how=\"outer\", on=[\"experiment\", \"reaction\"])\n",
    "    df = merged.groupby([\"reaction\", \"experiment\"]).agg(list).reset_index()\n",
    "    # metabolite part\n",
    "    metabolites = idata.posterior.mics.to_numpy()\n",
    "    concentrations = concat_experiments(idata.posterior.conc_train, \"mics\").melt(\n",
    "        id_vars=\"experiment\", var_name=\"metabolite\", value_name=\"concentration\"\n",
    "    )\n",
    "    cf = concentrations.groupby([\"metabolite\", \"experiment\"]).agg(list).reset_index()\n",
    "    cf.experiment = \"Posterior\"\n",
    "    return {\n",
    "        \"reactions\": df.reaction.to_list(),\n",
    "        \"box_y\": df.kcat.apply(lambda x: np.mean([np.log(i) for i in x])).to_list(),\n",
    "        \"left_y\": df.enzyme.apply(lambda x: [np.log(i) for i in x]).to_list(),\n",
    "        \"hover_y\": df.flux.to_list(),\n",
    "        \"colors\": df.flux.apply(np.mean).to_list(),\n",
    "        \"sizes\": df.flux.apply(np.mean).to_list(),\n",
    "        \"conditions\": df.experiment.to_list(),\n",
    "        \"met_sizes\": cf.concentration.apply(np.mean).to_list(),\n",
    "        \"met_colors\": cf.concentration.apply(np.mean).to_list(),\n",
    "        \"met_y\": cf.concentration.to_list(),\n",
    "        \"metabolites\": cf.metabolite.to_list(),\n",
    "        \"met_conditions\": cf.experiment.to_list(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfe2c79-1c2b-461e-a957-736387800e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:10.697054Z",
     "iopub.status.busy": "2023-09-27T15:16:10.695676Z",
     "iopub.status.idle": "2023-09-27T15:16:15.167930Z",
     "shell.execute_reply": "2023-09-27T15:16:15.166561Z",
     "shell.execute_reply.started": "2023-09-27T15:16:10.696976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shu_data = data_to_shu(idata, mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58927bb2-3a5f-4370-a915-cf368c44f621",
   "metadata": {},
   "source": [
    "Extra processing because python JSON is not strict JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0895e1-0672-4d52-8cc6-e3c98715e79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:15.172331Z",
     "iopub.status.busy": "2023-09-27T15:16:15.170811Z",
     "iopub.status.idle": "2023-09-27T15:16:15.547628Z",
     "shell.execute_reply": "2023-09-27T15:16:15.545182Z",
     "shell.execute_reply.started": "2023-09-27T15:16:15.172238Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, values in shu_data.items():\n",
    "    if key not in [\"reactions\", \"conditions\", \"metabolites\", \"met_conditions\"]:\n",
    "        for i in range(len(values)):\n",
    "            if isinstance(values[i], list):\n",
    "                shu_data[key][i] = [v if not isnan(v) else \"NaN\" for v in values[i]]\n",
    "            else:\n",
    "                shu_data[key][i] = values[i] if not isnan(values[i]) else \"NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3ff8b-658f-4be9-b433-7687e4bf4320",
   "metadata": {},
   "source": [
    "The drains will be mapped to reactions in the map which consumes the metabolites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb26a43-4157-4e12-91c3-bcc9cb1f86bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:15.550949Z",
     "iopub.status.busy": "2023-09-27T15:16:15.550245Z",
     "iopub.status.idle": "2023-09-27T15:16:15.564788Z",
     "shell.execute_reply": "2023-09-27T15:16:15.560363Z",
     "shell.execute_reply.started": "2023-09-27T15:16:15.550882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shu_data[\"reactions\"] = [\n",
    "    reac.replace(\"pepdrain\", \"PPC\").replace(\"pyrdrain\", \"PDH\")\n",
    "    if isinstance(reac, str)\n",
    "    else \"NaN\"\n",
    "    for reac in shu_data[\"reactions\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c759-ada7-4a1c-ae54-23b3b44af348",
   "metadata": {},
   "source": [
    "The following dumped data can be now imported by shu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2271910d-2a0f-4978-b969-5057da1fecb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T15:16:15.574877Z",
     "iopub.status.busy": "2023-09-27T15:16:15.574138Z",
     "iopub.status.idle": "2023-09-27T15:16:22.450299Z",
     "shell.execute_reply": "2023-09-27T15:16:22.447807Z",
     "shell.execute_reply.started": "2023-09-27T15:16:15.574799Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"../data/{OUTPUT_RESULTS}.metabolism.json\", \"w\") as f:\n",
    "    json.dump(shu_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maud-local",
   "language": "python",
   "name": "maud-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
