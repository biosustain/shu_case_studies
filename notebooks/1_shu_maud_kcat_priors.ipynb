{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eb8904-ec39-4533-937e-67fa19a382f5",
   "metadata": {},
   "source": [
    "# Maud to shu\n",
    "\n",
    "Example to generate [`shu`](https://github.com/biosustain/shu) inputs from [`Maud`](https://github.com/biosustain/Maud) output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8406b8-7d6f-47fb-be75-87b66729822e",
   "metadata": {},
   "source": [
    "It requires [Maud](https://github.com/biosustain/Maud) and [maudtools](https://github.com/biosustain/maudtools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b028e83-2758-403f-b4c9-9d43e600e960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:31.279439Z",
     "iopub.status.busy": "2023-04-14T11:05:31.278873Z",
     "iopub.status.idle": "2023-04-14T11:05:33.422103Z",
     "shell.execute_reply": "2023-04-14T11:05:33.421498Z",
     "shell.execute_reply.started": "2023-04-14T11:05:31.279378Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from math import isnan\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from maud.getting_idatas import get_idata\n",
    "from maud.loading_maud_inputs import MaudInput, load_maud_input\n",
    "from maud.utils import get_lognormal_parameters_from_quantiles\n",
    "from maudtools.plotting import concat_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fd1aa-e42b-4d3f-bd90-3d08d9930804",
   "metadata": {},
   "source": [
    "Load the input that was used to run `maud sample` and the output generated by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98372904-7d47-4843-90a9-f938e48a2849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.423293Z",
     "iopub.status.busy": "2023-04-14T11:05:33.422875Z",
     "iopub.status.idle": "2023-04-14T11:05:33.426493Z",
     "shell.execute_reply": "2023-04-14T11:05:33.425745Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.423272Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_RESULTS = \"maud_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aa88f9-25a0-4667-b3b3-fcd2fd4d2979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.428765Z",
     "iopub.status.busy": "2023-04-14T11:05:33.428207Z",
     "iopub.status.idle": "2023-04-14T11:05:33.909453Z",
     "shell.execute_reply": "2023-04-14T11:05:33.908846Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.428737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi = load_maud_input(f\"../data/{OUTPUT_RESULTS}/user_input\")\n",
    "idata = get_idata(glob(f\"../data/{OUTPUT_RESULTS}/samples/*csv\"), mi, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43da32d9-bc64-451f-90a9-2a2c8e7ee192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.910306Z",
     "iopub.status.busy": "2023-04-14T11:05:33.910108Z",
     "iopub.status.idle": "2023-04-14T11:05:33.915005Z",
     "shell.execute_reply": "2023-04-14T11:05:33.914421Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.910289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_experiments(infd, x_var: str = \"reactions\", experiments: list[str] = None):\n",
    "    if experiments is None:\n",
    "        experiments = infd.experiments\n",
    "    with_exp = {\n",
    "        exp.item(): pd.DataFrame(np.concatenate(infd[:, :, i, :]), columns=infd[x_var])\n",
    "        for i, exp in enumerate(experiments)\n",
    "    }\n",
    "    list(map(lambda x: x[1].insert(0, \"experiment\", x[0]), with_exp.items()))\n",
    "    return pd.concat(with_exp.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f367624-b220-46b2-868c-7f97bcca6c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.916045Z",
     "iopub.status.busy": "2023-04-14T11:05:33.915815Z",
     "iopub.status.idle": "2023-04-14T11:05:33.920570Z",
     "shell.execute_reply": "2023-04-14T11:05:33.919907Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.916024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q_exploc(kcat) -> tuple[float, float, str]:\n",
    "    \"\"\"Calculate mu and sigma of the underlying normal distribution from a Maud prior kcat.\"\"\"\n",
    "    mu, sigma = (\n",
    "        (np.log(kcat.exploc), kcat.scale)\n",
    "        if kcat.exploc is not None\n",
    "        else get_lognormal_parameters_from_quantiles(kcat.pct1, 0.01, kcat.pct99, 0.99)\n",
    "    )   \n",
    "    return mu, sigma, kcat.enzyme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b10a7-9f28-4935-b188-1f36c8e6a7ed",
   "metadata": {},
   "source": [
    "Functions to transform the data from the maud output into shu input.\n",
    "\n",
    "One function is used for reaction data and the other is for metabolite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae2735e-6cdb-48fb-b58a-bf79d2d24f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.921860Z",
     "iopub.status.busy": "2023-04-14T11:05:33.921586Z",
     "iopub.status.idle": "2023-04-14T11:05:33.936614Z",
     "shell.execute_reply": "2023-04-14T11:05:33.935904Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.921836Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_to_shu(idata: az.InferenceData, mi: MaudInput) -> Dict[str, List[float]]:\n",
    "    \"\"\"Plot kcats on the left, enzyme concentrations on the right, flux as hover and flux mean as color and size of arrows.\"\"\"\n",
    "    edge_list = [e.split(\"_\") for e in idata.posterior.edges.to_numpy() if \"_\" in e]\n",
    "    edges = {ed[1]: ed[0] for ed in edge_list}\n",
    "    edges_to_val = {ed[0]: ed[1] for ed in edge_list}\n",
    "    fluxes = concat_experiments(idata.posterior.flux_train, \"reactions\").melt(\n",
    "        id_vars=\"experiment\", var_name=\"reaction\", value_name=\"flux\"\n",
    "    )\n",
    "    conc_enzymes = concat_experiments(\n",
    "        idata.posterior.conc_enzyme_train,\n",
    "        \"enzymes\",\n",
    "        idata.posterior.conc_enzyme_train.experiments,\n",
    "    )\n",
    "    conc_enzymes.columns = [\n",
    "        idata.posterior.conc_enzyme_train[\"enzymes\"][0].values.tolist()\n",
    "        if col != \"experiment\"\n",
    "        else \"experiment\"\n",
    "        for col in conc_enzymes.columns\n",
    "    ]\n",
    "    conc_enzymes.columns = [\n",
    "        edges_to_val[col] if col != \"experiment\" else \"experiment\"\n",
    "        for col in conc_enzymes.columns\n",
    "    ]\n",
    "    conc_enzymes = conc_enzymes.melt(\n",
    "        id_vars=\"experiment\", var_name=\"reaction\", value_name=\"enzyme\"\n",
    "    )\n",
    "    #kcats = pd.DataFrame(\n",
    "    #    np.concatenate(idata.posterior.kcat), columns=idata.posterior[\"enzymes\"]\n",
    "    #)\n",
    "    #kcats.columns = [edges_to_val[col] for col in kcats.columns]\n",
    "    #kcats = kcats.melt(var_name=\"reaction\", value_name=\"kcat\")\n",
    "    #kcats[\"experiment\"] = \"Posterior\"\n",
    "    kcats_priors = pd.DataFrame(\n",
    "        [\n",
    "            (kcat[2], point, \"Prior\")\n",
    "            for kcat in [q_exploc(kcat) for kcat in mi.prior_input.kcat]\n",
    "            for point in np.random.lognormal(kcat[0], kcat[1], size=300)\n",
    "        ],\n",
    "        columns=[\"reaction\", \"kcat\", \"experiment\"]\n",
    "    )\n",
    "    kcats = kcats_priors\n",
    "    #kcats = pd.concat([kcats, kcats_priors])\n",
    "\n",
    "    for df in [fluxes, conc_enzymes, kcats]:\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"DRAIN\")]\n",
    "    merged = pd.concat(\n",
    "        [\n",
    "            df.sort_values([\"experiment\", \"reaction\"])\n",
    "            if i == 0\n",
    "            else df.sort_values([\"experiment\", \"reaction\"]).loc[\n",
    "                :, ~df.columns.isin([\"experiment\", \"reaction\"])\n",
    "            ]\n",
    "            for i, df in enumerate([fluxes, conc_enzymes])\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    merged.experiment = \"Posterior\"\n",
    "    merged = pd.merge(merged, kcats, how=\"outer\", on=[\"experiment\", \"reaction\"])\n",
    "    df = merged.groupby([\"reaction\", \"experiment\"]).agg(list).reset_index()\n",
    "    # metabolite part\n",
    "    metabolites = idata.posterior.mics.to_numpy()\n",
    "    concentrations = concat_experiments(idata.posterior.conc_train, \"mics\").melt(\n",
    "        id_vars=\"experiment\", var_name=\"metabolite\", value_name=\"concentration\"\n",
    "    )\n",
    "    cf = concentrations.groupby([\"metabolite\", \"experiment\"]).agg(list).reset_index()\n",
    "    cf.experiment = \"Posterior\"\n",
    "    return {\n",
    "        \"reactions\": df.reaction.to_list(),\n",
    "        # \"box_y\": df.enzyme.apply(lambda x: np.mean([np.log(i) for i in x])).to_list(),\n",
    "        \"box_y\": df.enzyme.apply(np.mean).to_list(),\n",
    "        \"left_y\": df.kcat.apply(lambda x: [np.log(i) for i in x]).to_list(),\n",
    "        #\"left_y\": df.kcat.to_list(),\n",
    "        \"hover_y\": df.flux.to_list(),\n",
    "        \"colors\": df.flux.apply(np.mean).to_list(),\n",
    "        \"sizes\": df.flux.apply(np.mean).to_list(),\n",
    "        \"conditions\": df.experiment.to_list(),\n",
    "        \"met_sizes\": cf.concentration.apply(np.mean).to_list(),\n",
    "        \"met_colors\": cf.concentration.apply(np.mean).to_list(),\n",
    "        # \"met_y\": cf.concentration.apply(lambda x: [np.log10(i) for i in x]).to_list(),\n",
    "        \"met_y\": cf.concentration.to_list(),\n",
    "        \"metabolites\": cf.metabolite.to_list(),\n",
    "        \"met_conditions\": cf.experiment.to_list(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfe2c79-1c2b-461e-a957-736387800e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:33.937790Z",
     "iopub.status.busy": "2023-04-14T11:05:33.937491Z",
     "iopub.status.idle": "2023-04-14T11:05:34.043172Z",
     "shell.execute_reply": "2023-04-14T11:05:34.042511Z",
     "shell.execute_reply.started": "2023-04-14T11:05:33.937767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shu_data = data_to_shu(idata, mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58927bb2-3a5f-4370-a915-cf368c44f621",
   "metadata": {},
   "source": [
    "Extra processing because python JSON is not strict JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0895e1-0672-4d52-8cc6-e3c98715e79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:34.044139Z",
     "iopub.status.busy": "2023-04-14T11:05:34.043912Z",
     "iopub.status.idle": "2023-04-14T11:05:34.050767Z",
     "shell.execute_reply": "2023-04-14T11:05:34.049988Z",
     "shell.execute_reply.started": "2023-04-14T11:05:34.044112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, values in shu_data.items():\n",
    "    if key not in [\"reactions\", \"conditions\", \"metabolites\", \"met_conditions\"]:\n",
    "        for i in range(len(values)):\n",
    "            if isinstance(values[i], list):\n",
    "                shu_data[key][i] = [v if not isnan(v) else \"NaN\" for v in values[i]]\n",
    "            else:\n",
    "                shu_data[key][i] = values[i] if not isnan(values[i]) else \"NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3ff8b-658f-4be9-b433-7687e4bf4320",
   "metadata": {},
   "source": [
    "The drains will be mapped to reactions in the map which consumes the metabolites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb26a43-4157-4e12-91c3-bcc9cb1f86bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:34.052019Z",
     "iopub.status.busy": "2023-04-14T11:05:34.051727Z",
     "iopub.status.idle": "2023-04-14T11:05:34.056914Z",
     "shell.execute_reply": "2023-04-14T11:05:34.056266Z",
     "shell.execute_reply.started": "2023-04-14T11:05:34.051979Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shu_data[\"reactions\"] = [\n",
    "    reac.replace(\"pepdrain\", \"PPC\").replace(\"pyrdrain\", \"PDH\")\n",
    "    if isinstance(reac, str)\n",
    "    else \"NaN\"\n",
    "    for reac in shu_data[\"reactions\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c759-ada7-4a1c-ae54-23b3b44af348",
   "metadata": {},
   "source": [
    "The following dumped data can be now imported by shu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f8e097-ee18-4a2b-a92e-84863b06fba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T11:05:34.057905Z",
     "iopub.status.busy": "2023-04-14T11:05:34.057679Z",
     "iopub.status.idle": "2023-04-14T11:05:34.092261Z",
     "shell.execute_reply": "2023-04-14T11:05:34.091646Z",
     "shell.execute_reply.started": "2023-04-14T11:05:34.057885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"../data/{OUTPUT_RESULTS}.metabolism.json\", \"w\") as f:\n",
    "    json.dump(shu_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maud-local",
   "language": "python",
   "name": "maud-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
